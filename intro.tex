\section{Introduction}

The end of classical device scaling means that the power per unit area on chip
is rising with each technology generation.  This implies that architectures for
future technology nodes will not be able to power-on all components of the chip
simultaneously, with some estimates being 50\% ``dark silicon'' by
8nm~\cite{isca11:dark-silicon}, which is less than 10 years away.  This trend,
the utilization wall, will curtail expected performance improvements.
Interestingly, much of the core's energy is not expended in the functional
units, but rather in the power-hungry structures needed for
attaining reasonable performance on general purpose workloads.  To exploit this,
architects have in part turned to hardware specialization and
accelerators, which sacrifice generality for efficiency in executing either
specific computations or computations for certain application domains.

Though accelerators hold great promise, with many new accelerator designs
showing significant efficiency and performance gains, the research and 
insights have been fragmented.  Newly proposed accelerators are evaluated 
in their own toolchain, generally with a specific general purpose core, and with 
a set of chosen benchmarks.  Solving this by integrating tens of accelerators 
into a single simulation system and developing compatible compilers 
for them is intractable due to development time.  This means that attaining 
insights into accelerators which transcends specific simulators, core design
points, evaluation metrics and applications is extremely difficult.
This limitation hinders our ability to understand the future of acceleration 
in terms of their behavior, design and use.
%benefit, and how can we do it?


The slowing of Mooreâ€™s law and Dennard scaling has also led a trend towards 
domain specific accelerators (DSAs) for performance and energy consumptioni~\cite{1815968}. 
DSAs are high performance computation engines for a specific domain. 
In essence, DSAs trade obsoletion for performance and energy efficiency. 
DSAs employ common specialization principles for concurrency, computation, 
communication, data reuse, and coordination, 
but sacrifice programmability completely. 
~\cite{nowatzki2016pushing} shows that a specialized architecture can be developed for 
general purpose programmability and be competitive 
against DSAs by trading only up to 3.8x in area and 4.1x in power. 


Figure~\ref{fig:proposed-work-overview} gives a high-level overview of each
proposed work compared to the current approaches for each problem, 
and they are outlined below.

\subsection{Document Overview}

Section~\ref{sec:tdg} describes completed work in using the TDG to model various forms of
acceleration, in terms of modeling and validation.  The next three sections
describe the proposed work: Section~\ref{sec:limits} for studying the limits
and opportunities, Section~\ref{sec:design} for using the TDG to aid the design
of new accelerators and Section~\ref{sec:multi-acc} for enabling practical
multi-acceleration.  Each section of proposed work contains a \emph{motivation}
section, a \emph{research approach} section to explain how we address the problem,
a \emph{preliminary results} section, a \emph{proposed work} section 
which overviews the remaining work to be done, and ends with \emph{related work}.
Section~\ref{sec:summary} summarizes the work, 
Section~\ref{sec:deliverables} outlines deliverables,
and Section~\ref{sec:timeline} describes the proposed dissertation schedule.


